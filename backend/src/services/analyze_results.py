import os
import json
from pathlib import Path
from typing import Dict, Any, List, Optional
import google.generativeai as genai
from pydantic import BaseModel
from dotenv import load_dotenv

from ..models.scan import ScanPlan

# .env dosyasƒ±nƒ± y√ºkle - mod√ºl y√ºklendiƒüinde
def _load_env_file():
    """
    .env dosyasƒ±nƒ± y√ºkle - birden fazla yolu dene
    √ñnce environment variable'ƒ± kontrol et, yoksa .env dosyasƒ±nƒ± ara
    """
    # √ñnce environment variable'ƒ± kontrol et (Docker Compose'dan gelebilir)
    api_key = os.getenv("GEMINI_API_KEY")
    if api_key:
        print(f"[SUCCESS] GEMINI_API_KEY environment variable'dan y√ºklendi, uzunluk: {len(api_key)}")
        return api_key
    
    # Environment variable yoksa .env dosyasƒ±nƒ± ara
    current_file = Path(__file__).resolve()
    
    # Proje root'u bul (backend/src/services -> backend -> SecTestOpsHub)
    project_root = current_file.parent.parent.parent.parent
    
    env_paths = [
        project_root / '.env',  # Proje root (en olasƒ±)
        current_file.parent.parent.parent / '.env',  # Backend klas√∂r√º
        Path.cwd() / '.env',  # √áalƒ±≈üma dizini
        Path.cwd().parent / '.env',  # √áalƒ±≈üma dizininin √ºst√º
    ]
    
    print(f"[DEBUG] Aranan .env yollarƒ±:")
    for path in env_paths:
        print(f"  - {path} (exists: {path.exists()})")
    
    for env_path in env_paths:
        if env_path.exists():
            try:
                # √ñnce load_dotenv ile dene
                load_dotenv(dotenv_path=env_path, override=True)
                
                # Tekrar environment variable'ƒ± kontrol et
                api_key = os.getenv("GEMINI_API_KEY")
                if api_key:
                    print(f"[SUCCESS] GEMINI_API_KEY .env dosyasƒ±ndan y√ºklendi: {env_path}")
                    print(f"[SUCCESS] API Key uzunluk: {len(api_key)}")
                    return api_key
                
                # Direkt dosyayƒ± da oku (daha g√ºvenilir)
                with open(env_path, 'r', encoding='utf-8') as f:
                    for line in f:
                        line = line.strip()
                        if line and not line.startswith('#') and '=' in line:
                            key, value = line.split('=', 1)
                            key = key.strip()
                            value = value.strip().strip('"').strip("'")
                            if key == 'GEMINI_API_KEY' and value:
                                os.environ['GEMINI_API_KEY'] = value
                                print(f"[SUCCESS] GEMINI_API_KEY direkt dosyadan y√ºklendi: {env_path}")
                                print(f"[SUCCESS] API Key uzunluk: {len(value)}")
                                return value
            except Exception as e:
                print(f"[ERROR] .env y√ºklenirken hata {env_path}: {e}")
                import traceback
                traceback.print_exc()
                continue
    
    print("[ERROR] GEMINI_API_KEY hi√ßbir .env dosyasƒ±nda bulunamadƒ±!")
    return None

# Mod√ºl y√ºklendiƒüinde API key'i kontrol et
print("[INFO] analyze_results.py mod√ºl√º y√ºkleniyor, GEMINI_API_KEY kontrol ediliyor...")
_loaded_api_key = _load_env_file()
if _loaded_api_key:
    print(f"[SUCCESS] Mod√ºl y√ºkleme sƒ±rasƒ±nda API key y√ºklendi")
else:
    print("[WARNING] Mod√ºl y√ºkleme sƒ±rasƒ±nda API key y√ºklenemedi, fonksiyon √ßaƒürƒ±sƒ±nda tekrar denenecek")


class ToolAnalysis(BaseModel):
    """Her tool i√ßin ayrƒ± analiz sonucu."""
    tool_name: str
    risk_level: str  # "critical", "high", "medium", "low", "safe"
    findings_count: int
    critical_findings: int
    high_findings: int
    medium_findings: int
    low_findings: int
    info_findings: int
    summary: str  # Tool √∂zelinde √∂zet
    key_issues: List[str]  # √ñnemli sorunlar
    recommendations: List[str]  # Tool √∂zelinde √∂neriler


class RiskLevelSummary(BaseModel):
    """Risk seviyesi √∂zeti."""
    critical: int = 0
    high: int = 0
    medium: int = 0
    low: int = 0
    info: int = 0


class SecurityRecommendation(BaseModel):
    """G√ºvenlik √∂nerisi."""
    priority: str  # "critical", "high", "medium", "low"
    title: str
    description: str
    affected_tools: List[str]  # Hangi ara√ßlardan geldiƒüi
    action_items: List[str]  # Yapƒ±lacaklar listesi


class AnalysisResult(BaseModel):
    """AI analiz sonucu."""
    target_url: str
    overall_risk_level: str  # "critical", "high", "medium", "low", "safe"
    risk_summary: RiskLevelSummary
    total_findings: int
    tool_analyses: List[ToolAnalysis]  # Her tool i√ßin ayrƒ± analiz
    recommendations: List[SecurityRecommendation]
    analysis_summary: str  # Genel analiz √∂zeti
    risk_table: Dict[str, Any]  # Risk seviyesi tablosu


def analyze_scan_results(scan_plan: ScanPlan) -> AnalysisResult:
    """
    Gemini AI kullanarak tarama sonu√ßlarƒ±nƒ± analiz eder.
    Her tool i√ßin ayrƒ± analiz yapar ve ortak rapor √ºretir.
    
    Args:
        scan_plan: Tarama planƒ± (t√ºm ara√ß sonu√ßlarƒ±)
        
    Returns:
        AnalysisResult: Analiz sonu√ßlarƒ±, risk seviyesi tablosu ve √∂neriler
    """
    # Gemini API key'i al - _load_env_file √∂nce environment variable'ƒ± kontrol eder
    api_key = _load_env_file()
    
    if not api_key:
        print("[ERROR] GEMINI_API_KEY y√ºklenemedi!")
    else:
        print(f"[INFO] GEMINI_API_KEY ba≈üarƒ±yla y√ºklendi, uzunluk: {len(api_key)}")
    
    if not api_key:
        # API key yoksa analiz yapmadan devam et
        return AnalysisResult(
            target_url=scan_plan.target_url,
            overall_risk_level="unknown",
            risk_summary=RiskLevelSummary(),
            total_findings=0,
            tool_analyses=[],
            recommendations=[],
            analysis_summary="Gemini AI API key ayarlanmamƒ±≈ü. L√ºtfen .env dosyasƒ±na GEMINI_API_KEY=your_key ekleyin ve backend'i yeniden ba≈ülatƒ±n.",
            risk_table={}
        )
    
    # Gemini AI'yƒ± yapƒ±landƒ±r
    genai.configure(api_key=api_key)
    
    # Model adƒ±nƒ± belirle - √∂nce mevcut modelleri listele
    model = None
    model_name = None
    
    try:
        # Mevcut modelleri listele
        available_models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
        print(f"[INFO] Mevcut Gemini modelleri: {available_models}")
        
        # √ñncelik sƒ±rasƒ±na g√∂re model dene (en yeni modeller √∂nce)
        model_candidates = [
            'models/gemini-2.5-flash',      # En yeni ve hƒ±zlƒ±
            'models/gemini-2.5-pro',        # En yeni ve g√º√ßl√º
            'models/gemini-2.0-flash',      # 2.0 flash
            'models/gemini-2.0-flash-exp',   # 2.0 experimental
            'models/gemini-1.5-flash',       # 1.5 flash (eski)
            'models/gemini-1.5-pro',        # 1.5 pro (eski)
            'models/gemini-pro',            # Eski model
            'gemini-2.5-flash',             # Prefix olmadan
            'gemini-2.5-pro',
            'gemini-2.0-flash',
            'gemini-1.5-flash',
            'gemini-1.5-pro',
            'gemini-pro'
        ]
        
        for candidate in model_candidates:
            # Model adƒ±nƒ± normalize et (models/ prefix'i ekle/√ßƒ±kar)
            normalized_name = candidate if candidate.startswith('models/') else f'models/{candidate}'
            
            # Mevcut modeller listesinde var mƒ± kontrol et
            if any(normalized_name in m or candidate in m for m in available_models):
                try:
                    model = genai.GenerativeModel(candidate)
                    model_name = candidate
                    print(f"[SUCCESS] Gemini model '{candidate}' ba≈üarƒ±yla y√ºklendi")
                    break
                except Exception as e:
                    print(f"[WARNING] Model '{candidate}' bulundu ama y√ºklenemedi: {e}")
                    continue
        
        # Hi√ßbiri √ßalƒ±≈ümadƒ±ysa, yine de en yaygƒ±n olanƒ± dene
        if not model:
            print("[WARNING] Mevcut modeller listesinde uygun model bulunamadƒ±, varsayƒ±lan modelleri deniyoruz...")
            for candidate in ['models/gemini-2.5-flash', 'models/gemini-2.5-pro', 'models/gemini-2.0-flash', 'gemini-pro', 'models/gemini-pro']:
                try:
                    model = genai.GenerativeModel(candidate)
                    model_name = candidate
                    print(f"[SUCCESS] Gemini model '{candidate}' ba≈üarƒ±yla y√ºklendi (varsayƒ±lan)")
                    break
                except Exception as e:
                    print(f"[WARNING] Model '{candidate}' y√ºklenemedi: {e}")
                    continue
                    
    except Exception as e:
        print(f"[WARNING] Model listesi alƒ±namadƒ±: {e}, varsayƒ±lan modelleri deniyoruz...")
        # ListModels ba≈üarƒ±sƒ±z olursa direkt model y√ºklemeyi dene
        for candidate in ['models/gemini-2.5-flash', 'models/gemini-2.5-pro', 'models/gemini-2.0-flash', 'models/gemini-1.5-flash', 'models/gemini-pro', 'gemini-pro']:
            try:
                model = genai.GenerativeModel(candidate)
                model_name = candidate
                print(f"[SUCCESS] Gemini model '{candidate}' ba≈üarƒ±yla y√ºklendi (fallback)")
                break
            except Exception as e2:
                print(f"[WARNING] Model '{candidate}' y√ºklenemedi: {e2}")
                continue
    
    if not model:
        error_msg = "Gemini model bulunamadƒ±. L√ºtfen API key'inizin ge√ßerli olduƒüundan ve model eri≈üiminizin olduƒüundan emin olun."
        print(f"[ERROR] {error_msg}")
        raise RuntimeError(error_msg)
    
    # Tool mapping ve normalize edilmi≈ü sonu√ßlarƒ± topla
    tool_results = {}
    result_mapping = {
        "ping": scan_plan.ping_result,
        "whois": scan_plan.whois_result,
        "nmap": scan_plan.nmap_result,
        "nikto": scan_plan.nikto_result,
        "gobuster": scan_plan.gobuster_result,
        "zap": scan_plan.zap_result,
        "testssl": scan_plan.testssl_result,
        "dnsrecon": scan_plan.dnsrecon_result,
        "theharvester": scan_plan.theharvester_result,
        "subfinder": scan_plan.subfinder_result,
    }
    
    for tool_name, result in result_mapping.items():
        if result and result.normalized_json:
            tool_results[tool_name] = result.normalized_json
    
    if not tool_results:
        return AnalysisResult(
            target_url=scan_plan.target_url,
            overall_risk_level="safe",
            risk_summary=RiskLevelSummary(),
            total_findings=0,
            tool_analyses=[],
            recommendations=[],
            analysis_summary="Tarama sonucu bulunamadƒ±.",
            risk_table={}
        )
    
    # Her tool i√ßin ayrƒ± analiz yap
    tool_analyses = []
    all_findings = []
    
    print(f"[INFO] Toplam {len(tool_results)} tool i√ßin analiz yapƒ±lacak: {list(tool_results.keys())}")
    
    for tool_name, normalized_data in tool_results.items():
        try:
            findings_count = len(normalized_data.get("findings", []))
            metrics_keys = list(normalized_data.get("metrics", {}).keys())
            print(f"[INFO] {tool_name} i√ßin AI analizi ba≈ülatƒ±lƒ±yor... (Findings: {findings_count}, Metrics: {metrics_keys})")
            
            tool_analysis = analyze_single_tool(model, tool_name, normalized_data, scan_plan.target_url)
            tool_analyses.append(tool_analysis)
            
            print(f"[SUCCESS] {tool_name} analizi tamamlandƒ±:")
            print(f"  - Risk Level: {tool_analysis.risk_level}")
            print(f"  - Summary: {tool_analysis.summary[:100]}...")
            print(f"  - Key Issues: {len(tool_analysis.key_issues)}")
            print(f"  - Recommendations: {len(tool_analysis.recommendations)}")
            
            # Findings'leri topla
            if normalized_data.get("findings"):
                for finding in normalized_data["findings"]:
                    finding["tool"] = tool_name
                    all_findings.append(finding)
        except Exception as e:
            # Tool analizi ba≈üarƒ±sƒ±z olursa devam et
            import traceback
            print(f"[ERROR] Tool {tool_name} analizi ba≈üarƒ±sƒ±z: {e}")
            print(f"[ERROR] Hata detayƒ±:\n{traceback.format_exc()}")
            # Hata olsa bile varsayƒ±lan bir analiz ekle
            tool_analyses.append(ToolAnalysis(
                tool_name=tool_name,
                risk_level="unknown",
                findings_count=len(normalized_data.get("findings", [])),
                critical_findings=0,
                high_findings=0,
                medium_findings=0,
                low_findings=0,
                info_findings=0,
                summary=f"{tool_name} analizi sƒ±rasƒ±nda hata olu≈ütu: {str(e)}",
                key_issues=[],
                recommendations=[]
            ))
            continue
    
    print(f"[INFO] Tool analizleri tamamlandƒ±. Toplam {len(tool_analyses)} analiz, {len(all_findings)} finding.")
    
    # Ortak analiz yap
    try:
        print(f"[INFO] Genel analiz ba≈ülatƒ±lƒ±yor...")
        overall_analysis = analyze_overall(model, tool_results, tool_analyses, scan_plan.target_url, all_findings)
        print(f"[SUCCESS] Genel analiz tamamlandƒ±:")
        print(f"  - Overall Risk: {overall_analysis.get('overall_risk_level')}")
        print(f"  - Recommendations: {len(overall_analysis.get('recommendations', []))}")
        print(f"  - Analysis Summary: {overall_analysis.get('analysis_summary', '')[:100]}...")
    except Exception as e:
        # Ortak analiz ba≈üarƒ±sƒ±z olursa varsayƒ±lan d√∂nd√ºr
        import traceback
        print(f"[ERROR] Ortak analiz ba≈üarƒ±sƒ±z: {e}")
        print(f"[ERROR] Hata detayƒ±:\n{traceback.format_exc()}")
        overall_analysis = {
            "overall_risk_level": "medium",
            "risk_summary": {"critical": 0, "high": 0, "medium": 0, "low": 0, "info": 0},
            "total_findings": len(all_findings),
            "recommendations": [],
            "analysis_summary": f"Analiz tamamlandƒ± ancak detaylƒ± deƒüerlendirme yapƒ±lamadƒ±. Hata: {str(e)}",
            "risk_table": {}
        }
    
    # Risk √∂zetini hesapla
    risk_summary = RiskLevelSummary(**overall_analysis.get("risk_summary", {}))
    
    # √ñnerileri olu≈ütur
    recommendations = [
        SecurityRecommendation(**rec) for rec in overall_analysis.get("recommendations", [])
    ]
    
    return AnalysisResult(
        target_url=scan_plan.target_url,
        overall_risk_level=overall_analysis.get("overall_risk_level", "safe"),
        risk_summary=risk_summary,
        total_findings=overall_analysis.get("total_findings", len(all_findings)),
        tool_analyses=tool_analyses,
        recommendations=recommendations,
        analysis_summary=overall_analysis.get("analysis_summary", ""),
        risk_table=overall_analysis.get("risk_table", {})
    )


def analyze_single_tool(model, tool_name: str, normalized_data: Dict[str, Any], target_url: str) -> ToolAnalysis:
    """Tek bir tool i√ßin detaylƒ± analiz yapar."""
    
    # Tool'a √∂zel prompt olu≈ütur - DETAYLI analiz i√ßin
    tool_prompts = {
        "nmap": """
Nmap tarama sonu√ßlarƒ±nƒ± DETAYLI analiz et. √ñzellikle ≈üunlara dikkat et:
- A√ßƒ±k portlar ve servisler: Hangi portlar a√ßƒ±k, hangi servisler √ßalƒ±≈üƒ±yor?
- Servis versiyonlarƒ±: Eski versiyonlar var mƒ±? Bilinen CVE'ler var mƒ±?
- ƒ∞≈ületim sistemi tespiti: OS bilgisi sƒ±zdƒ±rƒ±lƒ±yor mu?
- G√ºvenlik a√ßƒ±klarƒ±: CVE'ler, zafiyetler tespit edildi mi?
- Port yapƒ±landƒ±rmasƒ±: Gereksiz portlar a√ßƒ±k mƒ±? Firewall kurallarƒ± yeterli mi?
- Servis yapƒ±landƒ±rmasƒ±: Servisler g√ºvenli yapƒ±landƒ±rƒ±lmƒ±≈ü mƒ±?

Her bulgu i√ßin: Risk seviyesi, etki analizi, saldƒ±rƒ± senaryolarƒ± ve DETAYLI √ß√∂z√ºm √∂nerileri sun.
""",
        "zap": """
OWASP ZAP tarama sonu√ßlarƒ±nƒ± DETAYLI analiz et. √ñzellikle ≈üunlara dikkat et:
- Web uygulama g√ºvenlik a√ßƒ±klarƒ±: XSS, SQL Injection, CSRF, Command Injection vb.
- OWASP Top 10 riskler: T√ºm kategorileri kontrol et
- G√ºvenlik ba≈ülƒ±klarƒ±: CSP, X-Frame-Options, HSTS, X-Content-Type-Options eksik mi?
- Authentication/Authorization: Zayƒ±f kimlik doƒürulama, yetkilendirme sorunlarƒ±
- Session Management: Session g√ºvenliƒüi, cookie g√ºvenliƒüi
- Input Validation: Kullanƒ±cƒ± girdisi doƒürulama eksiklikleri
- Error Handling: Hata mesajlarƒ± bilgi sƒ±zdƒ±rƒ±yor mu?

Her bulgu i√ßin: Risk seviyesi, etki analizi, saldƒ±rƒ± senaryolarƒ±, kod √∂rnekleri ve DETAYLI √ß√∂z√ºm √∂nerileri sun.
""",
        "nikto": """
Nikto tarama sonu√ßlarƒ±nƒ± DETAYLI analiz et. √ñzellikle ≈üunlara dikkat et:
- Web sunucu yapƒ±landƒ±rma hatalarƒ±: Yanlƒ±≈ü yapƒ±landƒ±rƒ±lmƒ±≈ü ayarlar
- Eski yazƒ±lƒ±m versiyonlarƒ±: G√ºncellenmemi≈ü yazƒ±lƒ±mlar, bilinen zafiyetler
- G√ºvenlik a√ßƒ±klarƒ±: CVE'ler, bilinen zafiyetler
- Potansiyel g√ºvenlik riskleri: Gizli dosyalar, yedek dosyalar, bilgi sƒ±zƒ±ntƒ±larƒ±
- Sunucu ba≈ülƒ±klarƒ±: Server header bilgileri sƒ±zdƒ±rƒ±lƒ±yor mu?
- Dosya ve dizin ke≈üfi: Gizli dosyalar, dizin listeleme

Her bulgu i√ßin: Risk seviyesi, etki analizi, saldƒ±rƒ± senaryolarƒ± ve DETAYLI √ß√∂z√ºm √∂nerileri sun.
""",
        "testssl": """
testssl.sh SSL/TLS tarama sonu√ßlarƒ±nƒ± DETAYLI analiz et. √ñzellikle ≈üunlara dikkat et:
- SSL/TLS protokol desteƒüi: TLS 1.0, 1.1 gibi eski protokoller destekleniyor mu?
- Cipher suite g√ºvenliƒüi: Zayƒ±f ≈üifreleme algoritmalarƒ± kullanƒ±lƒ±yor mu?
- Sertifika sorunlarƒ±: Ge√ßersiz sertifika, s√ºresi dolmu≈ü sertifika, yanlƒ±≈ü CN
- G√ºvenlik a√ßƒ±klarƒ±: Heartbleed, POODLE, BEAST, CRIME, BREACH vb.
- Perfect Forward Secrecy: PFS destekleniyor mu?
- Certificate Transparency: CT kayƒ±tlarƒ± var mƒ±?

Her bulgu i√ßin: Risk seviyesi, etki analizi, saldƒ±rƒ± senaryolarƒ±, konfig√ºrasyon √∂rnekleri ve DETAYLI √ß√∂z√ºm √∂nerileri sun.
""",
        "gobuster": """
Gobuster dizin tarama sonu√ßlarƒ±nƒ± DETAYLI analiz et. √ñzellikle ≈üunlara dikkat et:
- Gizli dizinler ve dosyalar: Hangi dizinler/f dosyalar ke≈üfedildi?
- Y√∂netim panelleri: Admin paneli, y√∂netim aray√ºz√º eri≈üilebilir mi?
- Yedek dosyalar: .bak, .old, .backup gibi yedek dosyalar var mƒ±?
- API endpoint'leri: Gizli API'ler ke≈üfedildi mi?
- Bilgi sƒ±zƒ±ntƒ±sƒ±: Hassas bilgiler i√ßeren dosyalar eri≈üilebilir mi?
- Dosya izinleri: Dosyalar yanlƒ±≈ü izinlerle yapƒ±landƒ±rƒ±lmƒ±≈ü mƒ±?

Her bulgu i√ßin: Risk seviyesi, etki analizi, saldƒ±rƒ± senaryolarƒ± ve DETAYLI √ß√∂z√ºm √∂nerileri sun.
""",
        "dnsrecon": """
dnsrecon DNS tarama sonu√ßlarƒ±nƒ± DETAYLI analiz et. √ñzellikle ≈üunlara dikkat et:
- DNS kayƒ±t g√ºvenliƒüi: DNS kayƒ±tlarƒ± doƒüru yapƒ±landƒ±rƒ±lmƒ±≈ü mƒ±?
- DNSSEC durumu: DNSSEC etkin mi?
- Subdomain ke≈üfi: Beklenmeyen subdomain'ler var mƒ±?
- SPF, DMARC, DKIM kayƒ±tlarƒ±: E-posta g√ºvenliƒüi kayƒ±tlarƒ± var mƒ±?
- DNS bilgi sƒ±zƒ±ntƒ±sƒ±: DNS kayƒ±tlarƒ± fazla bilgi sƒ±zdƒ±rƒ±yor mu?
- Zone transfer: Zone transfer a√ßƒ±k mƒ±?

Her bulgu i√ßin: Risk seviyesi, etki analizi, saldƒ±rƒ± senaryolarƒ± ve DETAYLI √ß√∂z√ºm √∂nerileri sun.
""",
        "subfinder": """
Subfinder subdomain tarama sonu√ßlarƒ±nƒ± DETAYLI analiz et. √ñzellikle ≈üunlara dikkat et:
- Ke≈üfedilen subdomain'ler: Hangi subdomain'ler ke≈üfedildi?
- Subdomain g√ºvenliƒüi: Subdomain'ler g√ºvenli yapƒ±landƒ±rƒ±lmƒ±≈ü mƒ±?
- Potansiyel saldƒ±rƒ± y√ºzeyi: Hangi subdomain'ler saldƒ±rƒ±ya a√ßƒ±k?
- Gizli subdomain'ler: Beklenmeyen subdomain'ler var mƒ±?
- Subdomain takeover riski: Kullanƒ±lmayan subdomain'ler var mƒ±?

Her bulgu i√ßin: Risk seviyesi, etki analizi, saldƒ±rƒ± senaryolarƒ± ve DETAYLI √ß√∂z√ºm √∂nerileri sun.
""",
        "theharvester": """
theHarvester OSINT tarama sonu√ßlarƒ±nƒ± DETAYLI analiz et. √ñzellikle ≈üunlara dikkat et:
- A√ßƒ±ƒüa √ßƒ±kan bilgiler: Hangi bilgiler halka a√ßƒ±k?
- E-posta adresleri: E-posta adresleri sƒ±zdƒ±rƒ±lƒ±yor mu?
- Host ve IP bilgileri: IP adresleri, host bilgileri a√ßƒ±ƒüa √ßƒ±kmƒ±≈ü mƒ±?
- Bilgi sƒ±zƒ±ntƒ±sƒ± riskleri: Hassas bilgiler halka a√ßƒ±k mƒ±?
- Sosyal m√ºhendislik riskleri: Saldƒ±rganlar i√ßin bilgi kaynaƒüƒ± var mƒ±?
- Metadata sƒ±zƒ±ntƒ±sƒ±: Metadata'da hassas bilgiler var mƒ±?

Her bulgu i√ßin: Risk seviyesi, etki analizi, saldƒ±rƒ± senaryolarƒ± ve DETAYLI √ß√∂z√ºm √∂nerileri sun.
""",
        "whois": """
Whois tarama sonu√ßlarƒ±nƒ± DETAYLI analiz et. √ñzellikle ≈üunlara dikkat et:
- Domain kayƒ±t bilgileri: Domain bilgileri doƒüru mu?
- Registrar bilgileri: Registrar g√ºvenilir mi?
- Kayƒ±t tarihleri: Domain s√ºresi dolmak √ºzere mi?
- ƒ∞leti≈üim bilgileri: ƒ∞leti≈üim bilgileri g√ºncel mi? Gizlilik korumasƒ± var mƒ±?
- Domain hijacking riski: Domain ele ge√ßirilme riski var mƒ±?
- Bilgi sƒ±zƒ±ntƒ±sƒ±: WHOIS'te fazla bilgi sƒ±zdƒ±rƒ±lƒ±yor mu?

Her bulgu i√ßin: Risk seviyesi, etki analizi, saldƒ±rƒ± senaryolarƒ± ve DETAYLI √ß√∂z√ºm √∂nerileri sun.
""",
        "ping": """
Ping tarama sonu√ßlarƒ±nƒ± DETAYLI analiz et. √ñzellikle ≈üunlara dikkat et:
- Host eri≈üilebilirliƒüi: Host eri≈üilebilir mi?
- DNS √ß√∂z√ºmlemesi: DNS doƒüru √ßalƒ±≈üƒ±yor mu?
- Aƒü baƒülantƒ±sƒ±: Aƒü baƒülantƒ±sƒ± saƒülƒ±klƒ± mƒ±?
- Gecikme s√ºreleri: Y√ºksek gecikme var mƒ±?
- ICMP filtreleme: ICMP paketleri filtreleniyor mu? (G√ºvenlik a√ßƒ±sƒ±ndan)
- Host ke≈üfi: Host bilgileri sƒ±zdƒ±rƒ±lƒ±yor mu?

Her bulgu i√ßin: Risk seviyesi, etki analizi ve DETAYLI √ß√∂z√ºm √∂nerileri sun.
"""
    }
    
    tool_specific_guidance = tool_prompts.get(tool_name, "Bu tool'un sonu√ßlarƒ±nƒ± analiz et.")
    
    findings = normalized_data.get("findings", [])
    metrics = normalized_data.get("metrics", {})
    summary = normalized_data.get("summary", "")
    status = normalized_data.get("status", "unknown")
    
    # Severity sayƒ±larƒ±nƒ± hesapla
    critical_count = sum(1 for f in findings if f.get("severity") == "CRITICAL")
    high_count = sum(1 for f in findings if f.get("severity") == "HIGH")
    medium_count = sum(1 for f in findings if f.get("severity") == "MEDIUM")
    low_count = sum(1 for f in findings if f.get("severity") == "LOW")
    info_count = sum(1 for f in findings if f.get("severity") == "INFO")
    
    # Findings yoksa bile metrics'ten analiz yapƒ±labilir
    has_findings = len(findings) > 0
    findings_note = ""
    if not has_findings:
        findings_note = "\nNOT: Bu tool i√ßin findings listesi bo≈ü, ancak metrics (metrikler) bilgilerinden analiz yapabilirsin. Metrics'teki bilgileri kullanarak risk seviyesi belirle."
    else:
        findings_note = f"\n√ñNEMLƒ∞: {len(findings)} adet bulgu var. Her bulgunun 'evidence' alanƒ±nƒ± DETAYLI analiz et. √ñzellikle teknik detaylarƒ± (port numaralarƒ±, servis versiyonlarƒ±, URL'ler, alert bilgileri, CPE bilgileri vb.) deƒüerlendir."
    
    # Tool-specific detaylƒ± analiz notlarƒ±
    tool_specific_analysis = ""
    
    # NMAP i√ßin √∂zel analiz
    if tool_name == "nmap" and metrics.get("ports"):
        ports_info = []
        for port in metrics.get("ports", []):
            if port.get("state") == "open":
                port_str = f"Port {port.get('port')}/{port.get('protocol')}: {port.get('service', 'unknown')}"
                if port.get("version"):
                    port_str += f" - Versiyon: {port.get('version')}"
                if port.get("product"):
                    port_str += f" - √úr√ºn: {port.get('product')}"
                if port.get("cpe"):
                    port_str += f" - CPE: {port.get('cpe')}"
                ports_info.append(port_str)
        
        if ports_info:
            tool_specific_analysis += f"\n\nüîç NMAP A√áIK PORTLAR ({len(ports_info)} adet):\n" + "\n".join(ports_info)
            tool_specific_analysis += "\n\nBu a√ßƒ±k portlarƒ± DETAYLI analiz et:\n"
            tool_specific_analysis += "- Her portun g√ºvenlik riskini deƒüerlendir (eski versiyonlar, bilinen zafiyetler, CVE'ler)\n"
            tool_specific_analysis += "- Gereksiz a√ßƒ±k portlar var mƒ±? Gereksiz servisler kapatƒ±lmalƒ±\n"
            tool_specific_analysis += "- Servis versiyonlarƒ± g√ºncel mi? Eski versiyonlar HIGH/MEDIUM risk olu≈üturabilir\n"
            tool_specific_analysis += "- Bilinen g√ºvenlik a√ßƒ±klarƒ± olan servisler var mƒ±? CVE veritabanƒ±nƒ± kontrol et\n"
            tool_specific_analysis += "- Firewall kurallarƒ± yeterli mi? Gereksiz portlar kapatƒ±lmalƒ± mƒ±?\n"
            tool_specific_analysis += "- OS tespiti yapƒ±ldƒ± mƒ±? OS bilgisi sƒ±zdƒ±rƒ±lƒ±yor mu?\n"
    
    # ZAP i√ßin √∂zel analiz
    if tool_name == "zap" and metrics.get("risk_summary"):
        risk_summary = metrics.get("risk_summary", {})
        tool_specific_analysis += f"\n\nüîç ZAP Rƒ∞SK √ñZETƒ∞:\n"
        tool_specific_analysis += f"- Y√ºksek Risk: {risk_summary.get('high', 0)}\n"
        tool_specific_analysis += f"- Orta Risk: {risk_summary.get('medium', 0)}\n"
        tool_specific_analysis += f"- D√º≈ü√ºk Risk: {risk_summary.get('low', 0)}\n"
        tool_specific_analysis += f"- Bilgilendirme: {risk_summary.get('informational', 0)}\n"
        tool_specific_analysis += f"- Toplam Alert: {metrics.get('total_alerts', 0)}\n"
        tool_specific_analysis += "\nHer alert'i DETAYLI analiz et:\n"
        tool_specific_analysis += "- Alert t√ºr√º, risk seviyesi, etkilenen URL'ler\n"
        tool_specific_analysis += "- OWASP Top 10 kategorisine g√∂re sƒ±nƒ±flandƒ±r\n"
        tool_specific_analysis += "- XSS, SQL Injection, CSRF gibi yaygƒ±n a√ßƒ±klar var mƒ±?\n"
        tool_specific_analysis += "- G√ºvenlik ba≈ülƒ±klarƒ± eksik mi? (CSP, HSTS, X-Frame-Options)\n"
        tool_specific_analysis += "- Authentication/Authorization sorunlarƒ± var mƒ±?\n"
        
        if metrics.get("alerts"):
            high_alerts = [a for a in metrics.get("alerts", []) if a.get("risk") == "High"]
            medium_alerts = [a for a in metrics.get("alerts", []) if a.get("risk") == "Medium"]
            if high_alerts:
                tool_specific_analysis += f"\n‚ö†Ô∏è Y√úKSEK Rƒ∞SKLƒ∞ ALERT'LER ({len(high_alerts)} adet):\n"
                for alert in high_alerts[:5]:  # ƒ∞lk 5 tanesini g√∂ster
                    tool_specific_analysis += f"- {alert.get('name', 'Unknown')}: {alert.get('description', '')[:100]}...\n"
            if medium_alerts:
                tool_specific_analysis += f"\n‚ö†Ô∏è ORTA Rƒ∞SKLƒ∞ ALERT'LER ({len(medium_alerts)} adet):\n"
                for alert in medium_alerts[:5]:
                    tool_specific_analysis += f"- {alert.get('name', 'Unknown')}: {alert.get('description', '')[:100]}...\n"
    
    # Nikto i√ßin √∂zel analiz
    if tool_name == "nikto" and metrics.get("items_by_severity"):
        severity = metrics.get("items_by_severity", {})
        tool_specific_analysis += f"\n\nüîç NIKTO BULGU √ñZETƒ∞:\n"
        tool_specific_analysis += f"- Kritik: {severity.get('CRITICAL', 0)}\n"
        tool_specific_analysis += f"- Y√ºksek: {severity.get('HIGH', 0)}\n"
        tool_specific_analysis += f"- Orta: {severity.get('MEDIUM', 0)}\n"
        tool_specific_analysis += f"- D√º≈ü√ºk: {severity.get('LOW', 0)}\n"
        tool_specific_analysis += f"- Bilgi: {severity.get('INFO', 0)}\n"
        tool_specific_analysis += f"- Toplam: {metrics.get('total_items', 0)}\n"
        if metrics.get("server"):
            tool_specific_analysis += f"- Sunucu: {metrics.get('server')}\n"
        tool_specific_analysis += "\nHer bulguyu DETAYLI analiz et:\n"
        tool_specific_analysis += "- Web sunucu yapƒ±landƒ±rma hatalarƒ±\n"
        tool_specific_analysis += "- Eski yazƒ±lƒ±m versiyonlarƒ± ve bilinen zafiyetler\n"
        tool_specific_analysis += "- Gizli dosyalar, dizin listeleme sorunlarƒ±\n"
        tool_specific_analysis += "- G√ºvenlik ba≈ülƒ±klarƒ± eksiklikleri\n"
    
    # testssl i√ßin √∂zel analiz
    if tool_name == "testssl" and metrics.get("vulnerabilities"):
        vulns = metrics.get("vulnerabilities", {})
        protocols = metrics.get("protocols", {})
        tool_specific_analysis += f"\n\nüîç TESTSSL ANALƒ∞Z:\n"
        if protocols:
            tool_specific_analysis += f"Protokoller: {json.dumps(protocols, indent=2)}\n"
        if vulns:
            tool_specific_analysis += f"G√ºvenlik A√ßƒ±klarƒ±: {json.dumps(vulns, indent=2)}\n"
        if metrics.get("certificate"):
            cert = metrics.get("certificate", {})
            tool_specific_analysis += f"Sertifika: CN={cert.get('cn')}, Ge√ßerlilik={cert.get('validity_days')} g√ºn\n"
        tool_specific_analysis += "\nDETAYLI analiz et:\n"
        tool_specific_analysis += "- TLS protokol desteƒüi (TLS 1.0, 1.1 eski ve riskli)\n"
        tool_specific_analysis += "- Cipher suite g√ºvenliƒüi (zayƒ±f ≈üifreleme algoritmalarƒ±)\n"
        tool_specific_analysis += "- Sertifika sorunlarƒ± (ge√ßersiz, s√ºresi dolmu≈ü, yanlƒ±≈ü CN)\n"
        tool_specific_analysis += "- G√ºvenlik a√ßƒ±klarƒ± (Heartbleed, POODLE, BEAST, CRIME, BREACH)\n"
        tool_specific_analysis += "- Perfect Forward Secrecy (PFS) desteƒüi\n"
    
    # Gobuster i√ßin √∂zel analiz
    if tool_name == "gobuster" and metrics.get("findings_by_status"):
        findings_by_status = metrics.get("findings_by_status", {})
        tool_specific_analysis += f"\n\nüîç GOBUSTER BULGU √ñZETƒ∞:\n"
        tool_specific_analysis += f"- Toplam Bulgu: {metrics.get('total_findings', 0)}\n"
        for status, count in findings_by_status.items():
            tool_specific_analysis += f"- Status {status}: {count} adet\n"
        tool_specific_analysis += "\nDETAYLI analiz et:\n"
        tool_specific_analysis += "- Gizli dizinler ve dosyalar (y√∂netim panelleri, yedek dosyalar)\n"
        tool_specific_analysis += "- API endpoint'leri ve gizli endpoint'ler\n"
        tool_specific_analysis += "- Bilgi sƒ±zƒ±ntƒ±sƒ± riskleri (hassas dosyalar eri≈üilebilir mi?)\n"
        tool_specific_analysis += "- Dosya izinleri ve eri≈üim kontrol√º sorunlarƒ±\n"
        tool_specific_analysis += "- Yedek dosyalar (.bak, .old, .backup) var mƒ±?\n"
    
    # DNS tools i√ßin √∂zel analiz
    if tool_name in ["dnsrecon", "subfinder"] and metrics:
        if tool_name == "dnsrecon":
            tool_specific_analysis += f"\n\nüîç DNSRECON ANALƒ∞Z:\n"
            tool_specific_analysis += "DETAYLI analiz et:\n"
            tool_specific_analysis += "- DNS kayƒ±t g√ºvenliƒüi (A, AAAA, MX, TXT kayƒ±tlarƒ±)\n"
            tool_specific_analysis += "- DNSSEC durumu (etkin mi?)\n"
            tool_specific_analysis += "- SPF, DMARC, DKIM kayƒ±tlarƒ± (e-posta g√ºvenliƒüi)\n"
            tool_specific_analysis += "- Zone transfer a√ßƒ±klarƒ±\n"
            tool_specific_analysis += "- DNS bilgi sƒ±zƒ±ntƒ±sƒ± riskleri\n"
        elif tool_name == "subfinder":
            tool_specific_analysis += f"\n\nüîç SUBFINDER ANALƒ∞Z:\n"
            tool_specific_analysis += f"- Ke≈üfedilen Subdomain Sayƒ±sƒ±: {len(findings)}\n"
            tool_specific_analysis += "DETAYLI analiz et:\n"
            tool_specific_analysis += "- Ke≈üfedilen subdomain'ler ve g√ºvenlik durumlarƒ±\n"
            tool_specific_analysis += "- Subdomain takeover riskleri (kullanƒ±lmayan subdomain'ler)\n"
            tool_specific_analysis += "- Potansiyel saldƒ±rƒ± y√ºzeyi geni≈ülemesi\n"
    
    # Ping i√ßin √∂zel analiz
    if tool_name == "ping" and metrics:
        tool_specific_analysis += f"\n\nüîç PING ANALƒ∞Z:\n"
        tool_specific_analysis += f"- Eri≈üilebilirlik: {metrics.get('reachability', 'unknown')}\n"
        if metrics.get("resolved_ip"):
            tool_specific_analysis += f"- √á√∂z√ºmlenen IP: {metrics.get('resolved_ip')}\n"
        if metrics.get("rtt_ms"):
            rtt = metrics.get("rtt_ms", {})
            tool_specific_analysis += f"- Gecikme: Min={rtt.get('min')}ms, Avg={rtt.get('avg')}ms, Max={rtt.get('max')}ms\n"
        tool_specific_analysis += "DETAYLI analiz et:\n"
        tool_specific_analysis += "- Host eri≈üilebilirliƒüi ve aƒü baƒülantƒ±sƒ±\n"
        tool_specific_analysis += "- DNS √ß√∂z√ºmlemesi doƒüru mu?\n"
        tool_specific_analysis += "- ICMP filtreleme (g√ºvenlik a√ßƒ±sƒ±ndan)\n"
    
    # Whois i√ßin √∂zel analiz
    if tool_name == "whois" and metrics:
        tool_specific_analysis += f"\n\nüîç WHOIS ANALƒ∞Z:\n"
        if metrics.get("domain"):
            tool_specific_analysis += f"- Domain: {metrics.get('domain')}\n"
        if metrics.get("registrar"):
            tool_specific_analysis += f"- Registrar: {metrics.get('registrar')}\n"
        if metrics.get("dates"):
            dates = metrics.get("dates", {})
            tool_specific_analysis += f"- Olu≈üturulma: {dates.get('creation')}\n"
            tool_specific_analysis += f"- Son G√ºncelleme: {dates.get('updated')}\n"
            tool_specific_analysis += f"- Son Kullanma: {dates.get('expiry')}\n"
        tool_specific_analysis += "DETAYLI analiz et:\n"
        tool_specific_analysis += "- Domain kayƒ±t bilgileri ve g√ºvenlik durumu\n"
        tool_specific_analysis += "- Domain s√ºresi dolmak √ºzere mi? (hijacking riski)\n"
        tool_specific_analysis += "- ƒ∞leti≈üim bilgileri gizliliƒüi (WHOIS privacy)\n"
        tool_specific_analysis += "- Bilgi sƒ±zƒ±ntƒ±sƒ± riskleri\n"
    
    findings_note += tool_specific_analysis
    
    prompt = f"""
Sen bir siber g√ºvenlik uzmanƒ±sƒ±n ve penetrasyon testi uzmanƒ±sƒ±n. {tool_name.upper()} tool'unun tarama sonu√ßlarƒ±nƒ± DETAYLI bir ≈üekilde analiz et.

Hedef: {target_url}
Tool: {tool_name}
Durum: {status}
√ñzet: {summary}
Findings Sayƒ±sƒ±: {len(findings)}

{tool_specific_guidance}
{findings_note}

Tool Sonu√ßlarƒ± (JSON):
{json.dumps(normalized_data, indent=2, ensure_ascii=False)}

G√ñREVƒ∞N:
1. T√ºm bulgularƒ± (findings) ve metrikleri (metrics) DETAYLI analiz et
2. Findings'lerin 'evidence' alanlarƒ±nƒ± √ñZELLƒ∞KLE analiz et (port numaralarƒ±, servis versiyonlarƒ±, CPE bilgileri vb.)
3. Her bulgu i√ßin ger√ßek risk seviyesini belirle (findings'teki severity sadece ba≈ülangƒ±√ß, sen ger√ßek riski deƒüerlendir):
   - Eski servis versiyonlarƒ± ‚Üí HIGH/MEDIUM risk
   - Bilinen g√ºvenlik a√ßƒ±klarƒ± olan portlar ‚Üí CRITICAL/HIGH risk
   - Gereksiz a√ßƒ±k portlar ‚Üí MEDIUM/LOW risk
   - Kritik servisler (SSH, RDP, FTP) ‚Üí Yapƒ±landƒ±rmaya g√∂re risk deƒüi≈üir
4. Her sorun i√ßin UYGULANABƒ∞Lƒ∞R ve DETAYLI √ß√∂z√ºm √∂nerileri sun
5. √ñneriler ≈üunlarƒ± i√ßermeli:
   - Sorunun ne olduƒüu (a√ßƒ±klama)
   - Neden riskli olduƒüu (etki analizi)
   - Nasƒ±l √ß√∂z√ºleceƒüi (adƒ±m adƒ±m √ß√∂z√ºm)
   - Hangi dosya/ayar deƒüi≈üiklikleri gerektiƒüi
   - √ñrnek kod/konfig√ºrasyon (m√ºmk√ºnse)

√ñNEMLƒ∞: Findings'lerde severity "INFO" veya "LOW" olsa bile, ger√ßek g√ºvenlik riskine g√∂re risk_level belirle!
√ñrnekler:
- 4 a√ßƒ±k port varsa ve bunlar eski versiyonlu servisler ise ‚Üí risk_level "medium" veya "high"
- ZAP'te "informational" alert'ler bile g√ºvenlik ba≈ülƒ±klarƒ± eksikse ‚Üí risk_level "medium"
- Gobuster'da gizli dizinler bulunduysa ‚Üí risk_level "low" veya "medium"
- testssl'de eski TLS protokolleri destekleniyorsa ‚Üí risk_level "high"

L√ºtfen ≈üu formatta KISA ve PROFESYONEL analiz yap (SADECE JSON d√∂nd√ºr):
{{
  "risk_level": "critical|high|medium|low|safe|unknown",
  "summary": "Tool √∂zelinde KISA √∂zet analiz (T√ºrk√ße, 3-4 c√ºmle). √ñnemli bulgularƒ± ve risk seviyesini √∂z ≈üekilde a√ßƒ±kla.",
  "key_issues": [
    "Sorun 1: [Sorunun kƒ±sa a√ßƒ±klamasƒ±, hangi port/servis/URL, neden riskli, kƒ±sa etki analizi]",
    "Sorun 2: [Sorunun kƒ±sa a√ßƒ±klamasƒ±, hangi port/servis/URL, neden riskli, kƒ±sa etki analizi]",
    ...
  ],
  "recommendations": [
    "√ñneri 1: [Sorun] - √á√∂z√ºm: [Kƒ±sa √ß√∂z√ºm √∂zeti, hangi dosya/ayar, √∂rnek komut/konfig√ºrasyon]",
    "√ñneri 2: [Sorun] - √á√∂z√ºm: [Kƒ±sa √ß√∂z√ºm √∂zeti, hangi dosya/ayar, √∂rnek komut/konfig√ºrasyon]",
    ...
  ]
}}

√ñNEMLƒ∞ KURALLAR (T√úM TOOL'LAR ƒ∞√áƒ∞N):
- Summary: 3-4 c√ºmle, √∂z ve profesyonel
- Key issues: Her sorun 1-2 c√ºmle, teknik detaylar √∂z ≈üekilde
- Recommendations: Her √∂neri 2-3 c√ºmle, pratik √ß√∂z√ºm, √∂rnek komut/konfig√ºrasyon
- √ñrnek kod/konfig√ºrasyon ver (kƒ±sa ve √∂z - tek satƒ±r komut veya kƒ±sa config snippet)
- Findings yoksa bile metrics'ten analiz yap
- Her tool'un √∂zel analiz notlarƒ±nƒ± Dƒ∞KKATE AL
- Risk seviyesini ger√ßek g√ºvenlik durumuna g√∂re belirle
- Gereksiz tekrarlardan ka√ßƒ±n, √∂z ve net ol

SADECE JSON d√∂nd√ºr, ba≈üka a√ßƒ±klama ekleme.
"""
    
    try:
        print(f"[DEBUG] {tool_name} i√ßin Gemini AI analizi ba≈ülatƒ±lƒ±yor...")
        print(f"[DEBUG] Findings sayƒ±sƒ±: {len(findings)}, Metrics keys: {list(metrics.keys())}")
        
        response = model.generate_content(prompt)
        response_text = response.text.strip()
        
        print(f"[DEBUG] Gemini yanƒ±tƒ± alƒ±ndƒ±, uzunluk: {len(response_text)}")
        print(f"[DEBUG] ƒ∞lk 200 karakter: {response_text[:200]}")
        
        # JSON temizle
        if "```json" in response_text:
            response_text = response_text.split("```json")[1].split("```")[0].strip()
        elif "```" in response_text:
            response_text = response_text.split("```")[1].split("```")[0].strip()
        
        # JSON parse et
        try:
            analysis_data = json.loads(response_text)
        except json.JSONDecodeError as json_err:
            # JSON parse hatasƒ± - response_text'i d√ºzeltmeyi dene
            print(f"[WARNING] JSON parse hatasƒ±: {json_err}")
            print(f"[DEBUG] Parse edilemeyen metin: {response_text}")
            
            # Sadece JSON objesini bulmaya √ßalƒ±≈ü (i√ß i√ße objeler i√ßin)
            import re
            # ƒ∞√ß i√ße s√ºsl√º parantezleri sayarak JSON objesini bul
            start_idx = response_text.find('{')
            if start_idx != -1:
                brace_count = 0
                end_idx = start_idx
                for i in range(start_idx, len(response_text)):
                    if response_text[i] == '{':
                        brace_count += 1
                    elif response_text[i] == '}':
                        brace_count -= 1
                        if brace_count == 0:
                            end_idx = i + 1
                            break
                if end_idx > start_idx:
                    response_text = response_text[start_idx:end_idx]
                    analysis_data = json.loads(response_text)
                else:
                    raise json_err
            else:
                raise json_err
        
        print(f"[DEBUG] {tool_name} analizi ba≈üarƒ±lƒ±: risk_level={analysis_data.get('risk_level')}")
        
        return ToolAnalysis(
            tool_name=tool_name,
            risk_level=analysis_data.get("risk_level", "safe"),
            findings_count=len(findings),
            critical_findings=critical_count,
            high_findings=high_count,
            medium_findings=medium_count,
            low_findings=low_count,
            info_findings=info_count,
            summary=analysis_data.get("summary", ""),
            key_issues=analysis_data.get("key_issues", []),
            recommendations=analysis_data.get("recommendations", [])
        )
    except Exception as e:
        # Hata durumunda detaylƒ± log ve varsayƒ±lan d√∂nd√ºr
        import traceback
        error_trace = traceback.format_exc()
        print(f"[ERROR] {tool_name} analizi ba≈üarƒ±sƒ±z: {e}")
        print(f"[ERROR] Hata detayƒ±:\n{error_trace}")
        
        # Metrics'ten basit bir analiz yap
        fallback_summary = f"{tool_name} analizi tamamlandƒ±."
        if metrics:
            if tool_name == "ping":
                reachable = metrics.get("reachability", "unknown")
                if reachable == "up":
                    fallback_summary = f"Host eri≈üilebilir. Ping ba≈üarƒ±lƒ±."
                elif reachable == "down":
                    fallback_summary = f"Host eri≈üilebilir deƒüil."
            elif tool_name == "nmap":
                ports = metrics.get("ports", [])
                open_ports = [p for p in ports if isinstance(p, dict) and p.get("state") == "open"]
                if open_ports:
                    fallback_summary = f"{len(open_ports)} a√ßƒ±k port tespit edildi."
            elif tool_name == "whois":
                domain = metrics.get("domain")
                if domain:
                    fallback_summary = f"Domain bilgileri alƒ±ndƒ±: {domain}"
        
        return ToolAnalysis(
            tool_name=tool_name,
            risk_level="unknown",
            findings_count=len(findings),
            critical_findings=critical_count,
            high_findings=high_count,
            medium_findings=medium_count,
            low_findings=low_count,
            info_findings=info_count,
            summary=fallback_summary,
            key_issues=[],
            recommendations=[]
        )


def analyze_overall(model, tool_results: Dict[str, Dict], tool_analyses: List[ToolAnalysis], target_url: str, all_findings: List[Dict]) -> Dict[str, Any]:
    """T√ºm tool'larƒ± birle≈ütirerek ortak analiz yapar."""
    
    # Risk seviyesi sayƒ±larƒ±nƒ± topla
    total_critical = sum(ta.critical_findings for ta in tool_analyses)
    total_high = sum(ta.high_findings for ta in tool_analyses)
    total_medium = sum(ta.medium_findings for ta in tool_analyses)
    total_low = sum(ta.low_findings for ta in tool_analyses)
    total_info = sum(ta.info_findings for ta in tool_analyses)
    
    # Genel risk seviyesini belirle
    if total_critical > 0:
        overall_risk = "critical"
    elif total_high > 0:
        overall_risk = "high"
    elif total_medium > 0:
        overall_risk = "medium"
    elif total_low > 0:
        overall_risk = "low"
    else:
        overall_risk = "safe"
    
    prompt = f"""
Sen bir siber g√ºvenlik uzmanƒ±sƒ±n ve penetrasyon testi uzmanƒ±sƒ±n. A≈üaƒüƒ±daki t√ºm g√ºvenlik tarama sonu√ßlarƒ±nƒ± birle≈ütirerek KAPSAMLI ve DETAYLI bir g√ºvenlik analizi yap.

Hedef: {target_url}
Kullanƒ±lan Ara√ßlar: {', '.join(tool_results.keys())}

Tool Bazlƒ± Analizler:
{json.dumps([ta.model_dump() for ta in tool_analyses], indent=2, ensure_ascii=False)}

T√ºm Bulgular (ƒ∞lk 100):
{json.dumps(all_findings[:100], indent=2, ensure_ascii=False)}

Risk √ñzeti:
- Critical: {total_critical}
- High: {total_high}
- Medium: {total_medium}
- Low: {total_low}
- Info: {total_info}

G√ñREVƒ∞N:
1. T√ºm tool sonu√ßlarƒ±nƒ± birle≈ütirerek genel g√ºvenlik durumunu KISA ve PROFESYONEL deƒüerlendir
2. Tool'lar arasƒ± korelasyonlarƒ± bul (√∂rn: NMAP a√ßƒ±k port + ZAP XSS = y√ºksek risk)
3. Her √∂ncelik seviyesi i√ßin KISA ve UYGULANABƒ∞Lƒ∞R √∂neriler sun
4. √ñneriler ≈üunlarƒ± i√ßermeli (KISA):
   - Sorunun ne olduƒüu ve √∂ncelik seviyesi
   - Kƒ±sa etki analizi
   - Pratik √ß√∂z√ºm (3-4 adƒ±m)
   - Hangi dosya/ayar deƒüi≈ütirilmeli
   - √ñrnek komut/konfig√ºrasyon (kƒ±sa snippet)

L√ºtfen ≈üu formatta KAPSAMLI analiz yap (SADECE JSON d√∂nd√ºr):
{{
  "overall_risk_level": "critical|high|medium|low|safe",
  "risk_summary": {{
    "critical": {total_critical},
    "high": {total_high},
    "medium": {total_medium},
    "low": {total_low},
    "info": {total_info}
  }},
  "total_findings": {len(all_findings)},
  "recommendations": [
    {{
      "priority": "critical|high|medium|low",
      "title": "√ñneri ba≈ülƒ±ƒüƒ± (T√ºrk√ße, a√ßƒ±klayƒ±cƒ±)",
      "description": "DETAYLI a√ßƒ±klama (T√ºrk√ße, EN AZ 5-7 c√ºmle). Sorunun ne olduƒüu, neden riskli olduƒüu, etkisi, adƒ±m adƒ±m √ß√∂z√ºm, hangi dosyalar/ayarlar deƒüi≈ütirilmeli, √∂rnek kod/konfig√ºrasyon, test adƒ±mlarƒ±",
      "affected_tools": ["tool1", "tool2"],
      "action_items": [
        "Adƒ±m 1: [Detaylƒ± a√ßƒ±klama]",
        "Adƒ±m 2: [Detaylƒ± a√ßƒ±klama]",
        "Adƒ±m 3: [Detaylƒ± a√ßƒ±klama]"
      ]
    }}
  ],
  "analysis_summary": "Genel g√ºvenlik durumu DETAYLI √∂zeti (T√ºrk√ße, EN AZ 8-10 c√ºmle). T√ºm √∂nemli bulgularƒ±, riskleri, tool'lar arasƒ± korelasyonlarƒ± ve genel g√ºvenlik durumunu a√ßƒ±kla.",
  "risk_table": {{
    "critical": [
      {{"tool": "zap", "title": "Bulgu ba≈ülƒ±ƒüƒ±", "severity": "CRITICAL", "description": "Detaylƒ± a√ßƒ±klama", "port": null, "service": null, "recommendation": "√á√∂z√ºm √∂nerisi"}}
    ],
    "high": [
      {{"tool": "nmap", "title": "Bulgu ba≈ülƒ±ƒüƒ± (√∂rn: Port 22/ssh a√ßƒ±k - eski versiyon)", "severity": "HIGH", "description": "Detaylƒ± a√ßƒ±klama", "port": 22, "service": "ssh", "recommendation": "√á√∂z√ºm √∂nerisi"}}
    ],
    "medium": [
      {{"tool": "nmap", "title": "Bulgu ba≈ülƒ±ƒüƒ±", "severity": "MEDIUM", "description": "Detaylƒ± a√ßƒ±klama", "port": 80, "service": "http", "recommendation": "√á√∂z√ºm √∂nerisi"}}
    ],
    "low": [],
    "info": []
  }}
}}

√ñNEMLƒ∞ KURALLAR:
- EN AZ 5-7 √∂neri sun (critical ve high √∂ncelikli sorunlar i√ßin mutlaka √∂neri olmalƒ±)
- Her √∂nerinin "description" alanƒ± 2-3 c√ºmle olmalƒ±, √∂z ve teknik
- Her √∂nerinin "action_items" alanƒ± 3-4 adƒ±m i√ßermeli, kƒ±sa ve pratik
- √ñneriler tool'lar arasƒ± korelasyonlarƒ± da i√ßermeli
- √ñrnek komut/konfig√ºrasyon ver (kƒ±sa, tek satƒ±r veya snippet)
- Risk tablosunda her seviye i√ßin en √∂nemli bulgularƒ± listele (kƒ±sa a√ßƒ±klamalar)
- Gereksiz tekrarlardan ka√ßƒ±n, profesyonel ve √∂z ol

SADECE JSON d√∂nd√ºr, ba≈üka a√ßƒ±klama ekleme.
"""
    
    try:
        print(f"[DEBUG] Genel analiz i√ßin Gemini AI √ßaƒürƒ±sƒ± yapƒ±lƒ±yor...")
        response = model.generate_content(prompt)
        response_text = response.text.strip()
        
        print(f"[DEBUG] Genel analiz yanƒ±tƒ± alƒ±ndƒ±, uzunluk: {len(response_text)}")
        
        # JSON temizle
        if "```json" in response_text:
            response_text = response_text.split("```json")[1].split("```")[0].strip()
        elif "```" in response_text:
            response_text = response_text.split("```")[1].split("```")[0].strip()
        
        try:
            return json.loads(response_text)
        except json.JSONDecodeError as json_err:
            # JSON parse hatasƒ± - response_text'i d√ºzeltmeyi dene
            print(f"[WARNING] Genel analiz JSON parse hatasƒ±: {json_err}")
            print(f"[DEBUG] Parse edilemeyen metin (ilk 500 karakter): {response_text[:500]}")
            
            # ƒ∞√ß i√ße s√ºsl√º parantezleri sayarak JSON objesini bul
            start_idx = response_text.find('{')
            if start_idx != -1:
                brace_count = 0
                end_idx = start_idx
                for i in range(start_idx, len(response_text)):
                    if response_text[i] == '{':
                        brace_count += 1
                    elif response_text[i] == '}':
                        brace_count -= 1
                        if brace_count == 0:
                            end_idx = i + 1
                            break
                if end_idx > start_idx:
                    response_text = response_text[start_idx:end_idx]
                    return json.loads(response_text)
            
            raise json_err
    except Exception as e:
        # Hata durumunda varsayƒ±lan d√∂nd√ºr
        return {
            "overall_risk_level": overall_risk,
            "risk_summary": {
                "critical": total_critical,
                "high": total_high,
                "medium": total_medium,
                "low": total_low,
                "info": total_info
            },
            "total_findings": len(all_findings),
            "recommendations": [],
            "analysis_summary": f"Analiz tamamlandƒ±. {total_critical} kritik, {total_high} y√ºksek, {total_medium} orta seviye bulgu tespit edildi.",
            "risk_table": {}
        }
